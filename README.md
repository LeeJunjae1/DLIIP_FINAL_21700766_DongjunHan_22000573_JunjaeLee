# Vision-Based Intelligent Football Analytics

**Date:** 2025-June-02

**Author:** Dongjun Han 21700766, Junjae Lee 22000573

**Github:**  [repository link](https://github.com/LeeJunjae1/DLIIP_FINAL_21700766_DongjunHan_22000573_JunjaeLee)

**PDF version:** [PDF](./DLIP_FINAL_21700766_DongjunHan_22000573_JunjaeLee.pdf)

**Demo Video**: [Youtube_link](https://www.youtube.com/watch?v=00-XCQsEvEs)



## Introduction

 Analyzing key aspects of football â€” such as player tracking, ball possession, and event detection â€” presents significant challenges in the absence of computer vision. This difficulty is especially pronounced in fast-paced amateur or local matches, where gameplay is highly dynamic and unpredictable. Traditional manual analysis not only demands substantial time and effort, but is also highly prone to human error, making it impractical for regular use in grassroots or community-level games.

 To address these limitations, we propose an AI-powered computer vision system tailored specifically for football environments. By leveraging lightweight and efficient deep learning models, our system can detect players, estimate their trajectories and movement patterns, recognize critical events such as goals, and automatically generate highlight clips from raw video footage.

 This approach aims to democratize football analytics by bridging the technological gap between high-budget professional match analysis and everyday gameplay. Ultimately, it empowers amateur teams, coaches, and enthusiasts with accessible tools for performance evaluation, tactical feedback, and game review â€” previously available only at the professional level.

![intro](./img/intro_total.png)

<center><strong>Figure 1. AI-based Football Analysis (a) Video before analysis (b) Video with analysis applied</strong></center>



#### **Target Users**

- Amateur teams
- Youth academies
- School sports programs
- Local leagues

#### **Challenges They Face**

- High cost of equipment and software
- Lack of dedicated analysis staff
- Time-consuming manual review
- High technical barriers for setup and use

#### **Our Solution**

- Low-cost, fully automated match analysis
- Auto-generated highlight clips
- Real-time tracking and tactical feedback without human intervention



## Problem Statement

| No.  | Feature                                                      | Detailed Criteria                                            |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | **Detect players by team color**                             | - Players must be accurately classified into two teams based on vest color (e.g., red vs blue).<br> - Accuracy goal: â‰¥ 90% correct team classification per frame.<br> - Uses color thresholds in HSV |
| 2    | **Detect the ball**                                          | - Ball must be detected and tracked across frames.<br> - Detection accuracy goal: â‰¥ 85% presence in all frames where the ball is visible.<br> - Must handle small size, motion blur, and player occlusion. |
| 3    | **Visual trail effect for the ball**                         | - Ball path should be rendered as a fading line for the last few seconds.<br> - Must update in real-time and fade with transparency.<br> - Useful for visualizing speed and direction. |
| 4    | **Display player speed (km/h)**                              | - Compute speed using position displacement per frame.<br> - Calibrated to real-world scale using known field size.<br> - Display speed as a number above each player's bounding box. |
| 5    | **Display player activity (distance in meters)**             | - Cumulative distance tracked per player.<br> - Accuracy within Â±10% of actual path length (based on frame rate and calibration). |
| 6    | **Display team ball possession (%)**                         | - Based on time of control: who is nearest to the ball per frame.<br> - Rolling window or cumulative since start of half.<br> - Updated every second, rounded to nearest integer.<br> - Display with LED ring or UI bar.<br> - Must include serial output format: `"60,40"` for Red vs Blue. |
| 7    | **Draw field lines (corner, sideline, goal) with different colors** | - Overlay known field layout.<br> - Color-code: e.g., yellow (goal), light green (sideline), purple (corner).<br> - Must align to within Â±20 pixels of actual line. |
| 8    | **Detect and classify ball out-of-bound events (corner, sideline, goal)** | - Based on ball crossing predefined line boundaries.<br> - Event classification:<br>     - "GOAL": crosses goal line inside post<br>     - "Throw-In": crosses sideline<br>     - "Goal Line Out" : crosses goal line<br> - Trigger LED signal & log event with timestamp. |
| 9    | **Generate 2D heatmap of player movement**                   | - Create 2D heatmap for each player or team using accumulated positions.<br> - Update in real time or per session.<br> - Export as image or overlay on field.<br> - Resolution: at least 50Ã—30 grid cells. |
| 10   | **Create goal highlight clip and send by email**             | - Save 10-second video clip: 5s before + 5s after a "GOAL" event.<br> - Auto-generate using buffer frames.<br> - Send as email attachment (MP4 format, <20MB).<br> - Must include event timestamp in filename. |



### Task Distribution

**Dongjun**
 â†’ Responsible for tracking-based statistical analysis and numerical evaluation features, including team classification, player speed, distance covered, ball possession ratio, and 2D heatmap generation.

**Junjae**
 â†’ In charge of visual effects and event processing, including ball detection and trail rendering, field line recognition, out-of-bound classification, and automatic highlight generation.



## Requirement

### Hardware List

* LOLIN D32 Pro V2.0.0 ESP-32 WiFi-Bluetooth Combo

* 24 x WS2812B 5050 RGB LED RING-Black [SZH-LD088]

  


### Software Installation

* Python 3.9.18
* YOLO v8
* pytorch 2.1.2
* numpy 1.26.0
* ultralytics 8.0.140
* pyserial 3.5
* pygame 2.6.1
* OpenCV 4.11.0



## Dataset & Reference

#### **Dataset link**: 

- Football Video: [ì¶•êµ¬ë“œë¡ ì˜ìƒ\ VITNA FC ì¶•êµ¬]([[ì¶•êµ¬ë“œë¡ ì˜ìƒ\] VITNA FC ì¶•êµ¬ | 2023ë…„11ì›”4ì¼ - YouTube](https://www.youtube.com/watch?v=ZCv8W7u1-7A&t=1143s))



#### **Reference:**

- The initial ideas for person and ball detection, team classification, and ball possession tracking using YOLO were inspired by various video platforms such as YouTube. However, all datasets and code used in this project were developed independently without relying on any external references.



## Method

* This system analyzes futsal game footage in real time to detect match events (such as goals, throw-ins, and goal-line outs) and visually represents them by integrating with hardware (LEDs and ESP32).
* It also uses YOLOv8 and bytetrack to detect players and the ball, analyzing each player's activity level, speed, team classification, and ball possession. A highlight video is automatically saved and sent via email when specific events occur.
* YOLOv8 is used to detect players and the ball in the video (with the 'track' mode for players and 'predict' mode for the ball).
* The system was tested on various match videos to evaluate the accuracy of event detection. It was verified whether events such as goals, throw-ins, and goal-line outs matched the actual game situations. The consistency of player and ball detection was also checked, along with successful execution of highlight video saving and email-sending features.



## Algorithm

**Flow Chart**

<img src="./img/diagram.png" alt="diagram" style="zoom:80%;" />



## Procedure

### 1. Installation

**Anaconda settings**

before starting, check if the GPU driver for the cuda version is installed

```python
# Check your CUDA version
> nvidia-smi
```



```python
# Update CONDA in Base
conda update -n base -c defaults conda

# Create myEnv=yolov8
conda create -n yolov8 python=3.9.18 -y
conda activate yolov8

# Install Numpy, OpenCV, Matplot, Jupyter
conda install -c anaconda numpy=1.26.0 seaborn jupyter matplotlib -y
pip install opencv-python==4.11.0.86
pip install pyserial==3.5
pip install torchsummary
pip install onnx

conda install -c nvidia pytorch-cuda=11.8 -y
conda install -c pytorch pytorch=2.1.2 -y
conda install -c pytorch torchvision -y

pip install ultralytics==8.0.140  
pip install lapx>=0.5.2
pip install py-cpuinfo
```



**Additional installation required for music playback**

```python
pip install pygame==2.6.1
```



**Additional installation required for Arduino operation**

```python
pip install pyserial
```



---

### 2. Hardware Setting

 This project uses two main hardware components: the LOLIN D32 Pro V2.0.0 development board  and a 24-pixel WS2812B RGB LED ring module. The setup enables real-time visual feedback for both  possession percentages and match events such as goals or throw-ins in a futsal game analysis system.



#### 2.1. LOLIN D32 Pro V2.0.0 (ESP32 WiFi-Bluetooth Combo  Board)

 **Specifications:** 

* **Chipset**: Espressif ESP-WROVER (ESP32 dual-core MCU) 
* **Flash Memory**: 16MB PSRAM: 8MB 
* **Connectivity:** WiFi and Bluetooth combo 
* **Battery Support:** LiPo battery interface with charging circuit (max 500mA charging current) 
* **Peripheral Ports**: Built-in LOLIN I2C and TFT interface 
* **Storage**: MicroSD (TF) card slot with SPI mode support 
* **Arduino Compatible**



**Purpose in This Project:** 

 The LOLIN D32 Pro serves as the main controller for the system. It receives match data via serial  communication, processes it, and controls two LED rings using the FastLED library. The boardâ€™s  integrated MicroSD card slot also allows for potential expansion into logging or video synchronization.  Its dual-core processing capability ensures smooth handling of both data reception and LED  rendering.

![mcu_total](./img/mcu_total.png)

<center><strong>Figure 2.Â Image of LOLIN D32 Pro V2.0.0</strong></center>



#### 2.2. 24 x WS2812B RGB LED Ring Module (Black Circular Type)

**Specifications**: 

* **LED Type**: WS2812B (integrated RGB with data line control, NeoPixel compatible) 
* **Quantity**: 24 RGB LEDs arranged in a circular ring 
* **Outer Diameter**: 86mm 
* **Voltage:** 5V DC (operating range 4V ~ 7V) 
* **Data Protocol**: Single-wire control (compatible with FastLED and Adafruit NeoPixel libraries) 



**Pins Used:** 

* **Pin 27**: Used to control the â€œscoreâ€ LED ring for displaying team possession percentage. 

* **Pin 26**: Used to control the â€œeventâ€ LED ring for signaling game events such as goals or throw-ins. 

  

**Purpose in This Project:** 

Two identical 24-LED rings were used for dual visual outputs: 

1. **Possession Indicator (LED_PIN_SCORE â€“ Pin 27)** 
   * Displays red/blue division based on current possession ratio (e.g., 50:50). 
   * Dynamically updated upon receiving serial input such as  "60, 40".
2. **Event Display (LED_PIN_EVENT â€“ Pin 26)**
   * Visually emphasizes special game events.
   * Animated rainbow (goal), fluorescent green (throw-in), or purple (out), with fallback to white  when idle.

 The ring format offers a clear, easily interpretable visual interface suitable for real-time audience  feedback or player analysis.



![led_total](./img/led_total.png)

<center><strong>Figure 3. Image of 24 x WS2812B RGB LED Ring Module</strong></center>

---

### 3. LED Logic and Functionality

 The hardware logic is divided into two primary LED output systems controlled via two digital pins on  the LOLIN D32 Pro board:



#### 3.1. Ball Possession Visualization (Pin 27)

 Pin 27 controls a 24-LED WS2812B ring dedicated to displaying real-time ball possession ratio  between two teamsâ€”Red and Blue. 

* The possession percentage is calculated based on time accumulation: as each team gains  control of the ball over time, their possession ratio increases. 
* For instance, if the red team has had possession for 60% of the total elapsed time and the blue  team for 40%, the ring will light up 14 LEDs in red and 10 LEDs in blue (since 14/24 â‰ˆ 58.3%,  rounded). 
* This ratio is updated dynamically via serial input in the format  "60,40" (representing red and  blue percentages), and the LED ring visually reflects this balance in real-time. 

 This provides a clear and immediate visual representation of which team is dominating possession  during the match.



![ball_total](./img/ball_total.png)

<center><strong>Figure 4. Visualization of ball possession using LEDs</strong></center>



#### 3.2. Event Indicator (Pin 26)

 Pin 26 controls a second 24-LED WS2812B ring that reflects in-game events through distinct light  animations and colors: 

* **White (Default)**: When no specific event is active, the ring remains white, serving as a neutral  standby state. 
* **Fluorescent Green â€“ â€œTHROWINâ€**: Triggered when the ball goes out for a throw-in. The ring  glows solid bright green to indicate the restart type. 
* **Vivid Purple â€“ â€œOUTâ€**: Activated when the ball crosses the goal line but no goal is scored (e.g.,  goal kick or corner). The ring turns solid fluorescent purple. 
* **Rainbow Wave â€“ â€œGOALâ€**: When a goal is scored, the ring enters a dynamic rainbow animation  that creates a wave-like motion, emphasizing the celebratory nature of the moment. 

 These effects are triggered via serial commands ( "GOAL" ,  "THROWIN" , or  "OUT" ), and automatically  reset to white after a fixed duration, creating a visually engaging and intuitive event feedback  system for viewers or players.



![goal_total](./img/goal_total.png)

<center><strong>Figure 5. Event representation using LEDs. (a) Default (b) THORWIN (c) OUT (d) GOAL</strong></center>

-----

### 4. 'bytetrack.yaml' Setting

* The  bytetrack.yaml file can be found at the following relative path from the project root: 

**File Path**:  User's environment path

```python
import ultralytics
import os

# ultralytics ì„¤ì¹˜ ìœ„ì¹˜ í™•ì¸
ultralytics_path = os.path.dirname(ultralytics.__file__)

# bytetrack.yaml íŒŒì¼ ê²½ë¡œ êµ¬ì„±
bytetrack_yaml_path = os.path.join(ultralytics_path, 'cfg', 'trackers', 'bytetrack.yaml')

print("ByteTrack.yaml ê²½ë¡œ:", bytetrack_yaml_path)
```



####  4.1. Purpose of This File

 This configuration file defines the default settings used when applying the ByteTrack tracker in the  Ultralytics YOLO framework. While YOLO is responsible for object detection, ByteTrack builds on  YOLOâ€™s output to associate and track detected objects across frames. 

 The file includes key hyperparameters that control how detected objects are matched, tracked, and  maintained over time, directly influencing the stability and accuracy of object tracking.



#### 4.2. Modified Parameters and Explanation

##### 4.2.1. track_high_thresh: 0.001

**Original Purpose:**

 This parameter defines the confidence threshold for the first association step in tracking. Only  detections with confidence above this threshold are considered for matching with existing tracks.

**Reason for Modification**:

 By lowering the value from a typical setting (e.g., 0.5) to 0.001, nearly all detections, including those  with very low confidence, are included in the initial matching step.  This helps ensure that even uncertain detections are not prematurely discarded and can still be  linked to existing object tracks.



##### 4.2.2. track_low_thresh: 0.001 

**Original Purpose:**  

 Used in the second association step for unmatched tracks. It defines the minimum confidence  required for a detection to be considered as a match for remaining unmatched tracks. 

**Reason for Modification:**  

 Setting this to 0.001 means that essentially all detections will be evaluated for second-step matching.  This helps retain tracks even if the detection confidence is low, improving track continuity in difficult  conditions (e.g., occlusion, motion blur). 



##### 4.2.3. match_thresh: 0.9  

**Original Purpose:**  

 This parameter sets the IOU (Intersection over Union) threshold used to determine whether a  detection sufficiently overlaps with a track to be considered the same object. 

**Reason for Modification:**  

 Raising this threshold to 0.9 (from a typical value like 0.7) enforces stricter spatial matching,  reducing the risk of incorrectly associating different objects.  While this improves tracking accuracy, it may increase the number of new IDs created due to the  stricter matching criteria.





####  4.3. ByteTrack Configuration

 The following configuration file defines key parameters for the ByteTrack object tracking algorithm  within the Ultralytics YOLO framework. ByteTrack is responsible for maintaining consistent object IDs  across video frames based on bounding box matching and confidence thresholds. This configuration  has been tuned to improve object continuity and tracking robustness under challenging conditions.

```python
# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

# Default Ultralytics settings for ByteTrack tracker when using mode="track"
# For documentation and examples see https://docs.ultralytics.com/modes/track/
# For ByteTrack source code see https://github.com/ifzhang/ByteTrack

tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']
track_high_thresh: 0.001 # threshold for the first association
track_low_thresh: 0.001 # threshold for the second association
new_track_thresh: 0.25 # threshold for init new track if the detection does not match any tracks
track_buffer: 30 # buffer to calculate the time when to remove tracks
match_thresh: 0.9 # threshold for matching tracks
fuse_score: True # Whether to fuse confidence scores with the iou distances before matching
# min_box_area: 10  # threshold for min box areas(for tracker evaluation, not used for now)

```

![bytrack_ex](./img/bytrack_ex.png)

<center><strong>Figure 6. Example of bytetrack.yaml configuration</strong></center>

---

### 5. Python Code Integrated with ESP-32

 Using HoughLinesP, the system detects lines on a futsal field from video input to determine events such as throw-ins, out-of-bounds, and goals. These events are then visually represented through hardware integration with the ESP-32.

 YOLOv8 is employed to detect humans and the soccer ball, enabling further analysis. Players are classified into two teams, and metrics such as player speed, activity level, and team ball possession are calculated.

 The ball's movement is visualized in real time by tracking its trail. When a goal is detected, a highlight video is automatically saved, and an email is sent to the scoring team.

**Full Code**: [Github Link](https://github.com/LeeJunjae1/DLIIP_FINAL_21700766_DongjunHan_22000573_JunjaeLee) (Download all files from the repository to run the program)



#### 5.1. Code for Running the ESP-32

**Purpose:**

 This code is used to visualize events through hardware. It is crucial to check the serial port before use. In Visual Studio Code, the ESP-32 operates according to the specified flag provided during execution.

 By default, the LED is white. It turns green for a throw-in, purple for a goal-line out, and displays rainbow colors when a goal is scored.



**5.1.1. Initial Setup in VSCode**

* Used to configure the initial settings for integrating the ESP-32. The port (e.g., COM3) should be adjusted according to the user's environment.

```python
# ì‹œë¦¬ì–¼ í¬íŠ¸ ì—°ê²°, ESP-32ì™€ ì—°ë™

# COM3ì˜ ê²½ìš° ë³€ë™ì´ í•„ìš”. ì‚¬ìš©ìì˜ ì„¤ì •ì— ë”°ë¼ ë³€ê²½ í•„ìš”
try:
    ser = serial.Serial('COM3', 115200)
    print("ì‹œë¦¬ì–¼ í¬íŠ¸ ì—°ê²° ì„±ê³µ")
except serial.SerialException as e:
    print("ì‹œë¦¬ì–¼ í¬íŠ¸ ì—°ê²° ì‹¤íŒ¨:", e)
    ser = None

```

* The active port can be identified in the Ports section of the Device Manager

<img src="./img/port.jpg" alt="port" style="zoom:70%;" />

<center><strong>Figure 7. Port Check Example</strong></center>



**5.1.2. Serial Transmission within the Real-Time Video Analysis Code**

* When an event occurs, a corresponding flag is sent to the ESP-32. The ESP-32 then operates according to the received flag. The LED indicates each event with a specific color: purple for a goal-line out, green for a throw-in, and rainbow for a goal.

``` python
# 6. ì‹œë¦¬ì–¼ ì „ì†¡ (í•­ìƒ ì‹œë„)
if ser:  # ì‹œë¦¬ì–¼ í¬íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ì—´ë ¤ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹¤í–‰
    try:
        # 1. ì´ë²¤íŠ¸ ì „ì†¡ ìš°ì„  (ë³€í™” ìˆì„ ë•Œë§Œ)
        current_event = ""  # í˜„ì¬ ì´ë²¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”

        if goal_flag:
            current_event = "GOAL"  # ê³¨ì´ ë°œìƒí–ˆì„ ê²½ìš° "GOAL" ì´ë²¤íŠ¸ë¡œ ì„¤ì •
        elif throwin_flag:
            current_event = "THROWIN"  # ìŠ¤ë¡œì¸ ìƒí™©ì´ë©´ "THROWIN"
        elif goal_line_flag:
            current_event = "OUT"  # ê³µì´ ê³¨ë¼ì¸ì„ ë²—ì–´ë‚œ ê²½ìš° "OUT"

        if current_event != "":
            # ì´ë²¤íŠ¸ê°€ ë°œìƒí•œ ê²½ìš° (ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´) ì‹œë¦¬ì–¼ë¡œ ì „ì†¡
            ser.write(f"{current_event}\n".encode())

        # 2. ì ìœ ìœ¨ ì „ì†¡ (í•­ìƒ ë˜ëŠ” ì£¼ê¸°ì  í˜¹ì€ ë³€í™”ê°€ ìˆì„ ë•Œë§Œ)
        current_possession = f"{int(red_pct)},{int(blue_pct)}"

        if current_possession != last_possession_sent:
            # ì´ì „ì— ë³´ë‚¸ ì ìœ ìœ¨ê³¼ ë‹¤ë¥¼ ê²½ìš°ì—ë§Œ ì „ì†¡í•˜ì—¬ ì¤‘ë³µ ì „ì†¡ ë°©ì§€
            ser.write(f"{current_possession}\n".encode())
            last_possession_sent = current_possession  # ë§ˆì§€ë§‰ìœ¼ë¡œ ë³´ë‚¸ ì ìœ ìœ¨ ê°±ì‹ 

    except serial.SerialException:
        # ì‹œë¦¬ì–¼ í†µì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¶œë ¥
        print("ì‹œë¦¬ì–¼ ì „ì†¡ ì‹¤íŒ¨")

```





#### 5.2. Line Detection Process

**Purpose:**

 Used to detect lines on the futsal field, apply color overlays to the image, and determine whether an event is a goal-line out, goal, or throw-in.



**5.2.1 ROI Application Function**

* Since areas outside the field lines are not of interest, masking is applied to exclude them.

```python
# í•„ë“œ ë¼ì¸ë”°ê¸° (í•„ë“œ ì™¸ê³½ í…Œë‘ë¦¬ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë§ˆìŠ¤í¬ ìƒì„± í•¨ìˆ˜)
def get_border_mask(frame):
    h, w = frame.shape[:2]  # í”„ë ˆì„ì˜ ë†’ì´(h)ì™€ ë„ˆë¹„(w)ë¥¼ ê°€ì ¸ì˜´

    mask = np.zeros((h, w), dtype=np.uint8)  # ë™ì¼í•œ í¬ê¸°ì˜ ê²€ì€ìƒ‰ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ìƒì„± (ì´ˆê¸°ê°’ 0)

    # ROI(ê´€ì‹¬ ì˜ì—­, Region of Interest) ì„¤ì •: í•„ë“œ ì™¸ê³½ ì˜ì—­ ë‹¤ê°í˜•
    outer_polygon = np.array([[750, 40], [480, 995], [1760, 995], [1350, 40]])
    cv2.fillPoly(mask, [outer_polygon], 255)  # ì™¸ê³½ ë‹¤ê°í˜• ë¶€ë¶„ì„ í°ìƒ‰(255)ìœ¼ë¡œ ì±„ì›€

    # ë‚´ë¶€ ì˜ì—­ ì„¤ì •: í•„ë“œ ì¤‘ì•™ ìª½ì„ ë‹¤ì‹œ 0ìœ¼ë¡œ ë§Œë“¤ì–´ í…Œë‘ë¦¬ë§Œ ë‚¨ê¹€
    inner_polygon = np.array([[780, 60], [550, 955], [1680, 955], [1320, 60]])
    cv2.fillPoly(mask, [inner_polygon], 0)  # ë‚´ë¶€ ë‹¤ê°í˜• ì˜ì—­ì„ ë‹¤ì‹œ ê²€ì •ìƒ‰(0)ìœ¼ë¡œ ë®ì–´ ì§€ì›€

    return mask  # ìµœì¢…ì ìœ¼ë¡œ í…Œë‘ë¦¬ë§Œ ë‚¨ì€ ë§ˆìŠ¤í¬ ë°˜í™˜

```



**5.2.2. Function to Find Intersections**

* Detects four main lines within the futsal field. Even if the detected lines are short, they can be extended to form the full boundaries of the futsal field. By calculating the intersection points of these extended lines, the field lines can be accurately represented.

```python
def intersection(line1, line2):
    # ë‘ ì§ì„ (line1, line2)ì˜ êµì ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    # ê° ì§ì„ ì€ ê¸°ìš¸ê¸°(m)ì™€ yì ˆí¸(b)ìœ¼ë¡œ í‘œí˜„ë¨: y = mx + b
    m1, b1 = line1
    m2, b2 = line2

    # 1. ë‘˜ ë‹¤ ìˆ˜ì§ì„ ì¸ ê²½ìš° (ê¸°ìš¸ê¸°ê°€ ì—†ìŒ): x = b í˜•íƒœ -> êµì  ì—†ìŒ
    if m1 is None and m2 is None:
        return None  # ë‘ ìˆ˜ì§ì„ ì´ í‰í–‰í•˜ë©´ êµì  ì—†ìŒ

    # 2. ì²« ë²ˆì§¸ ì„ ë§Œ ìˆ˜ì§ì„ ì¸ ê²½ìš°: x = b1
    if m1 is None:
        x = b1  # ìˆ˜ì§ì„ ì€ x=b1 ì´ë¯€ë¡œ x ì¢Œí‘œëŠ” b1
        y = m2 * x + b2  # ë‘ ë²ˆì§¸ ì„ ì˜ y ê°’ì„ ê³„ì‚°
        return int(x), int(y)  # ì •ìˆ˜í˜• ì¢Œí‘œë¡œ ë°˜í™˜

    # 3. ë‘ ë²ˆì§¸ ì„ ë§Œ ìˆ˜ì§ì„ ì¸ ê²½ìš°: x = b2
    if m2 is None:
        x = b2  # x ì¢Œí‘œëŠ” b2
        y = m1 * x + b1  # ì²« ë²ˆì§¸ ì„ ì—ì„œì˜ yê°’ ê³„ì‚°
        return int(x), int(y)

    # 4. ë‘ ì§ì„ ì´ ì„œë¡œ í‰í–‰í•œ ê²½ìš° (ê¸°ìš¸ê¸°ê°€ ê°™ìŒ)
    if m1 == m2:
        return None  # í‰í–‰ì„ ì€ êµì  ì—†ìŒ

    # 5. ì¼ë°˜ì ì¸ ê²½ìš°: ë‘ ì„ ì˜ êµì  ê³„ì‚°
    x = (b2 - b1) / (m1 - m2)  # ë‘ ì„ ì˜ êµì  xì¢Œí‘œ ê³„ì‚°
    y = m1 * x + b1  # xë¥¼ ì´ìš©í•´ y ì¢Œí‘œ ê³„ì‚°

    return int(x), int(y)  # ì •ìˆ˜í˜• íŠœí”Œë¡œ ë°˜í™˜

```



**5.2.3. Function to Find the Equation of a Line**

* To extend a line, it is necessary to determine the linear equation representing that line. Once the equation is obtained, lines of any desired length can be freely drawn.

```python
def line_equation(x1, y1, x2, y2):
    # y = mx + b í˜•íƒœì˜ ì§ì„  ë°©ì •ì‹ ë°˜í™˜ (m, b)
    if x2 - x1 == 0:  # ìˆ˜ì§ì„  ì²˜ë¦¬
        return None, x1
    m = (y2 - y1) / (x2 - x1)
    b = y1 - m * x1
    return m, b
```



**5.2.4. Line Detection within the Real-Time Video Analysis Code**

* Lines are detected using HoughLinesP. To reduce noise, lines shorter than a specified length are ignored. Since the futsal field lines are primarily white, lines with a low white ratio in the HSV color space are also filtered out. Among horizontal lines, the top line of the frame is selected as the one with the smallest y-coordinate, and the bottom line is the one with the largest y-coordinate. For vertical lines, the leftmost line is chosen as the one closest to the left edge of the frame, and the rightmost line is the one closest to the right edge. Drawing lines are displayed in green, goal-line outs in purple, and goal lines in yellow.

```python
detected_lines = [] # ë¼ì¸ ê²€ì¶œ
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_copy = frame.copy()    
    
    # ì²« ë²ˆì§¸ í”„ë ˆì„ì—ì„œë§Œ ë¼ì¸ ê²€ì¶œì„ ìˆ˜í–‰í•˜ì—¬ í•„ë“œ ë¼ì¸ì„ ì¶”ì •
    if first_frame:
        gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # ë¸”ëŸ¬ë§ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        edges = cv2.Canny(blurred, 50, 150)  # Canny ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì—£ì§€ ê²€ì¶œ
        edges_masked = cv2.bitwise_and(edges, edges, mask=border_mask)  # í•„ë“œ í…Œë‘ë¦¬ ë§ˆìŠ¤í¬ ì ìš©

        # í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ì§ì„  ê²€ì¶œ
        lines = cv2.HoughLinesP(edges_masked, 1, np.pi / 180, threshold=50,
                                minLineLength=30, maxLineGap=30)

        h, w = frame.shape[:2]

        # HSV ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜ í›„ í°ìƒ‰ ë²”ìœ„ ì„¤ì • (í•„ë“œ ë¼ì¸ì„ ìœ„í•œ ë§ˆìŠ¤í¬)
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        lower_white = np.array([0, 0, 120])
        upper_white = np.array([180, 60, 255])

        # ê²€ì¶œëœ ë¼ì¸ì´ ìˆì„ ê²½ìš°
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]

                # ë¼ì¸ì˜ ì–‘ ë ì ì´ trapezoid (ROI) ì•ˆì— ìˆì–´ì•¼ í•¨
                p1_in = cv2.pointPolygonTest(trapezoid_pts.astype(np.float32), (float(x1), float(y1)), False) >= 0
                p2_in = cv2.pointPolygonTest(trapezoid_pts.astype(np.float32), (float(x2), float(y2)), False) >= 0
                if not (p1_in and p2_in):
                    continue

                # ë„ˆë¬´ ì§§ì€ ë¼ì¸ì€ ì œì™¸
                length = math.hypot(x2 - x1, y2 - y1)
                if length < 150:
                    continue

                # ê°ë„ ê³„ì‚°
                angle = abs(np.degrees(np.arctan2(y2 - y1, x2 - x1)))

                # ìœ„/ì•„ë˜ ëì— ë„ˆë¬´ ê°€ê¹Œìš´ ë¼ì¸ì€ ì œì™¸
                if angle <= 30 and (y1 >= 990 or y2 >= 990) or (y1 < 40 or y2 < 40):
                    continue
                if angle > 30 and (y1 >= 990 or y2 >= 990) or (y1 < 40 or y2 < 40):
                    continue

                # ë¼ì¸ ì˜ì—­ì—ì„œ í°ìƒ‰ ë¹„ìœ¨ í™•ì¸
                x_min = max(min(x1, x2), 0)
                y_min = max(min(y1, y2), 0)
                x_max = min(max(x1, x2), w - 1)
                y_max = min(max(y1, y2), h - 1)
                roi = hsv[y_min:y_max + 1, x_min:x_max + 1]
                if roi.size == 0:
                    continue

                # í°ìƒ‰ ë¹„ìœ¨ ê³„ì‚° (0.05ë³´ë‹¤ ì‘ìœ¼ë©´ ì œì™¸)
                white_mask_roi = cv2.inRange(roi, lower_white, upper_white)
                white_ratio = cv2.countNonZero(white_mask_roi) / (roi.shape[0] * roi.shape[1] + 1e-5)
                if white_ratio <= 0.05:
                    continue

                # ê¸°ì¤€ì ê³¼ ê¸°ìš¸ê¸° ì •ë³´ ì €ì¥
                rep_x, rep_y = (x1, y1) if y1 < y2 else (x2, y2)
                y_base_x = x1 if y1 > y2 else x2
                detected_lines.append(((x1, y1, x2, y2), rep_x, angle, y_base_x))

        first_frame = False  # ì´í›„ í”„ë ˆì„ì—ì„œëŠ” ë¼ì¸ ì¬ê²€ì¶œí•˜ì§€ ì•ŠìŒ

    # ê²€ì¶œëœ ë¼ì¸ë“¤ì„ ë°©í–¥ë³„ë¡œ ë¶„ë¥˜
    left_lines = [line for line in detected_lines if max(line[0][0], line[0][2]) < 900 and line[2] > 30]
    right_lines = [line for line in detected_lines if min(line[0][0], line[0][2]) >= 900 and line[2] > 30]
    top_lines = [line for line in detected_lines if (line[2] <= 40 or line[2] >= 150) and (40 < min(line[0][1], line[0][3]) < 100)]
    bottom_lines = [line for line in detected_lines if (line[2] <= 40 or line[2] >= 150) and min(line[0][1], line[0][3]) >= 900]

    # ìƒë‹¨ ë¼ì¸: ê°€ì¥ ìœ„ìª½(y ì¢Œí‘œê°€ ê°€ì¥ ì‘ì€ ë¼ì¸)
    top_line = min(top_lines, key=lambda l: min(l[0][1], l[0][3])) if top_lines else None
    # í•˜ë‹¨ ë¼ì¸: ê°€ì¥ ì•„ë˜ìª½(y ì¢Œí‘œê°€ ê°€ì¥ í° ë¼ì¸)
    bottom_line = max(bottom_lines, key=lambda l: max(l[0][1], l[0][3])) if bottom_lines else None
    # ì™¼ìª½ ë¼ì¸: ê¸°ì¤€ yê°€ ê°€ì¥ í° ì„ 
    left_line = max(left_lines, key=lambda l: l[3]) if left_lines else None
    # ì˜¤ë¥¸ìª½ ë¼ì¸: ê¸°ì¤€ yê°€ ê°€ì¥ í° ì„ 
    right_line = max(right_lines, key=lambda l: l[3]) if right_lines else None

    # ê° ì§ì„ ì— ëŒ€í•´ (ê¸°ìš¸ê¸°, ì ˆí¸) ê³„ì‚°
    lines_eq = {}
    for name, line in zip(["left", "right", "top", "bottom"], [left_line, right_line, top_line, bottom_line]):
        if line is None:
            lines_eq[name] = None
        else:
            x1, y1, x2, y2 = line[0]
            m, b = line_equation(x1, y1, x2, y2)
            lines_eq[name] = (m, b)

    # ê° ì„  ê°„ êµì  ê³„ì‚° (ì™¼-ìœ„, ìœ„-ì˜¤, ì˜¤-ì•„ë˜, ì•„ë˜-ì™¼ ìˆœì„œ)
    if None not in (lines_eq["left"], lines_eq["top"], lines_eq["right"], lines_eq["bottom"]):
        pt_left_top = intersection(lines_eq["left"], lines_eq["top"])
        pt_top_right = intersection(lines_eq["top"], lines_eq["right"])
        pt_right_bottom = intersection(lines_eq["right"], lines_eq["bottom"])
        pt_bottom_left = intersection(lines_eq["bottom"], lines_eq["left"])
        pts = [pt_left_top, pt_top_right, pt_right_bottom, pt_bottom_left]

        # êµì ì´ ëª¨ë‘ ì¡´ì¬í•˜ë©´ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        if all(pt is not None for pt in pts):
            for i in range(4):
                x1, y1 = pts[i]
                x2, y2 = pts[(i + 1) % 4]

                dx = x2 - x1
                dy = y2 - y1
                angle = abs(np.degrees(np.arctan2(dy, dx)))  # ë¼ì¸ì˜ ê¸°ìš¸ê¸°

                # ì‚¬ì´ë“œ ë¼ì¸ (ìˆ˜ì§ì— ê°€ê¹Œì›€): í˜•ê´‘ ì´ˆë¡
                if 40 < angle < 150:
                    color = (57, 255, 20)
                    cv2.line(frame_copy, (x1, y1), (x2, y2), color, 3)

                    # ì™¼ìª½ì´ë©´ throwin ê¸°ì¤€ì  ì €ì¥
                    m, b = line_equation(x1, y1, x2, y2)
                    if max(x1, x2) < 900:
                        if m is not None:
                            throwin_line_x = max(x1, x2)
                        left_m, left_b = m, b
                    else:
                        if m is not None:
                            throwin_line_x = max(x1, x2)
                        right_m, right_b = m, b

                # ê³¨ë¼ì¸ ë˜ëŠ” ì½”ë„ˆí‚¥ ë¼ì¸ (ìˆ˜í‰ì— ê°€ê¹Œì›€): í˜•ê´‘ ë³´ë¼
                else:
                    color = (255, 0, 255)
                    cv2.line(frame_copy, (x1, y1), (x2, y2), color, 3)

                    m, b = line_equation(x1, y1, x2, y2)
                    if m is not None:
                        x_mid = (x1 + x2) // 2
                        offset = 100 if max(y1, y2) >= 800 else 50
                        x_left = x_mid - offset
                        x_right = x_mid + offset
                        y_left = int(m * x_left + b)
                        y_right = int(m * x_right + b)

                        # ìœ íš¨ ë²”ìœ„ ë‚´ì˜ ì ì´ë©´ ë…¸ë€ ì„  ê·¸ë¦¬ê¸°
                        if 0 <= x_left < w and 0 <= x_right < w and 0 <= y_left < h and 0 <= y_right < h:
                            cv2.line(frame_copy, (x_left, y_left), (x_right, y_right), (0, 255, 255), 4)

                            # ìµœìƒë‹¨ ë…¸ë€ì„ ì´ë©´ ë³„ë„ ì €ì¥
                            if y_left < 100 or y_right < 100:
                                yellow_line_top = (x_left, x_right, y_left, y_right)
                            yellow_line = (x_left, x_right, y_left, y_right)

```



#### 5.3. Dimming the Area Outside the Soccer Field

**Purpose:**

 To help focus more on the soccer field by dimming the area outside the field.



**5.3.1. Code for Dimming the Area Outside the Soccer Field within the Real-Time Video Analysis**

* Masking is applied to extract the areas outside the region of interest. Then, transparency is applied to these areas to make them less visible, allowing better focus on the interior of the soccer field.

```python
trapezoid_pts = np.array([[750, 40], [480, 995], [1760, 995], [1350, 40]]) # ê´€ì‹¬ì—†ëŠ” ì˜ì—­ì„ ì–´ë‘¡ê²Œ í•˜ê¸° ìœ„í•œ ì¢Œí‘œ


frame_copy = frame.copy()    

# ê´€ì‹¬ ìˆëŠ” ì˜ì—­(ì‚¬ë‹¤ë¦¬ê¼´ ì˜ì—­)ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í™”ë©´ì„ ì–´ë‘¡ê²Œ ì²˜ë¦¬í•˜ì—¬ ê°•ì¡°í•˜ê¸° ìœ„í•œ ì½”ë“œ
# ì‚¬ë‹¤ë¦¬ê¼´ ëª¨ì–‘ì˜ ê´€ì‹¬ ì˜ì—­ ì¢Œí‘œ ì„¤ì • (ì¢Œìƒ, ì¢Œí•˜, ìš°í•˜, ìš°ìƒ)
trapezoid_pts = np.array([[740, 20], [430, 1050], [1830, 1050], [1360, 30]])
# ì›ë³¸ í”„ë ˆì„ê³¼ ë™ì¼í•œ í¬ê¸°ì˜ ê²€ì€ ë§ˆìŠ¤í¬ ìƒì„±
mask = np.zeros_like(frame_copy, dtype=np.uint8)
# ê´€ì‹¬ ì˜ì—­ì„ í•˜ì–€ìƒ‰ìœ¼ë¡œ ì±„ì›€
cv2.fillPoly(mask, [trapezoid_pts], (255, 255, 255))
# ê´€ì‹¬ ì˜ì—­ì˜ ë°˜ì „ ë§ˆìŠ¤í¬ ìƒì„± 
inv_mask = cv2.bitwise_not(mask)
# ê²€ì€ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
black_overlay = np.zeros_like(frame_copy, dtype=np.uint8)
# íˆ¬ëª…ë„ ì„¤ì • 
alpha = 0.5
# ê´€ì‹¬ ì—†ëŠ” ì˜ì—­ë§Œ ì˜¤ë²„ë ˆì´ ì²˜ë¦¬: ê²€ì€ ë°°ê²½ê³¼ ì›ë³¸ ì˜ìƒì˜ ë¹„ìœ¨ë¡œ í•©ì„±
overlay = cv2.addWeighted(
    cv2.bitwise_and(black_overlay, inv_mask), alpha,  # ì–´ë‘ìš´ ì˜ì—­
    cv2.bitwise_and(frame_copy, inv_mask), 1 - alpha, # ì›ë³¸ ì˜ì—­
    0  # ê°ë§ˆ ë³´ì • ì—†ìŒ
)
# ê´€ì‹¬ ì˜ì—­ì€ ì›ë³¸ ì˜ìƒ ê·¸ëŒ€ë¡œ, ë‚˜ë¨¸ì§€ëŠ” ì˜¤ë²„ë ˆì´ ì ìš©ëœ ì˜ìƒ ê²°í•©
frame_copy = cv2.bitwise_or(overlay, cv2.bitwise_and(frame_copy, mask))

```



#### 5.4. Player Detection

**Purpose:**

 To calculate player speed, activity level, and team classification, it is necessary to detect players in the video. YOLOv8â€™s â€œtrackâ€ mode is used to maintain consistent IDs for detected players across frames. This reduces errors when calculating playersâ€™ speed and activity levels.



**5.4.1. Player Detection within the Real-Time Video Analysis Code (Team Classification, Speed Calculation, Activity Calculation)**

* Players are classified into teams using HSV color space. Based on the uniform colors, players are divided into the red team and the blue team, with weighted color values applied to improve classification accuracy. YOLOv8 provides player coordinates, which are used along with frame-to-frame changes to calculate player speed and activity level. Activity is expressed in meters by applying a scale of 0.02 meters per pixel, while speed is expressed in kilometers per hour (km/h). Additionally, people detected outside the soccer field are excluded to ensure only players within the field are analyzed.

```python
frame_count += 1 #í”„ë ˆì„ ìˆ˜ ì¦ê°€
current_players = {}

# ì‚¬ëŒì„ ì°¾ê¸° ìœ„í•´, ì‚¬ëŒì„ ëˆ„ì í•´ì„œ ê²€ì¶œ ì§„í–‰
results = model.track(source=frame, persist=True, conf=0.001, iou=0.5, classes=[0], tracker="bytetrack.yaml")
    

# ì‚¬ëŒì„ ê°ì§€í•œ ê²½ìš° ì²˜ë¦¬
if results and results[0].boxes is not None:
    boxes = results[0].boxes
    xyxy = boxes.xyxy.cpu().numpy()  # ì‚¬ëŒë§ˆë‹¤ ê²½ê³„ ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
    confs = boxes.conf.cpu().numpy()  # ê° ë°•ìŠ¤ì˜ ì‹ ë¢°ë„ ì ìˆ˜
    ids = boxes.id.cpu().numpy().astype(int) if boxes.id is not None else range(len(xyxy))  # ê°ì²´ ID (ì—†ìœ¼ë©´ ì¸ë±ìŠ¤)

    for i in range(len(xyxy)):
        x1, y1, x2, y2 = map(int, xyxy[i])  # ê²½ê³„ ë°•ìŠ¤ ì¢Œí‘œ ì •ìˆ˜í™”
        conf = confs[i]
        obj_id = ids[i]  # ê° ê°ì²´ì˜ ê³ ìœ  ID

        # ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚°
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

        # ê²½ê¸°ì¥ ë°–ì— ìˆëŠ” ê²½ìš° ë¬´ì‹œ
        if cx > 1500 or cy > 1500:
            continue

        # ë°•ìŠ¤ ì¢Œí‘œê°€ ì´ë¯¸ì§€ ì˜ì—­ì„ ë„˜ì§€ ì•Šë„ë¡ ë³´ì •
        x1_clamped = max(0, x1)
        y1_clamped = max(0, y1)
        x2_clamped = min(frame.shape[1], x2)
        y2_clamped = min(frame.shape[0], y2)

        # ì„ ìˆ˜ì˜ ROI(ì˜ì—­) ì¶”ì¶œ
        roi = frame[y1_clamped:y2_clamped, x1_clamped:x2_clamped]

        # ë¹ˆ ROIëŠ” ë¬´ì‹œ
        if roi.size == 0:
            continue

        # HSV ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜ (íŒ€ ë¶„ë¥˜ë¥¼ ìœ„í•´)
        hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

        # ë¹¨ê°„ìƒ‰ ë²”ìœ„ ë§ˆìŠ¤í¬ ìƒì„± (ë‘ ê°œì˜ hue ì˜ì—­ + ë§ˆì  íƒ€ ê³„ì—´)
        red1 = cv2.inRange(hsv_roi, np.array([0, 40, 40]), np.array([20, 255, 255]))
        red2 = cv2.inRange(hsv_roi, np.array([160, 40, 40]), np.array([180, 255, 255]))
        magenta = cv2.inRange(hsv_roi, np.array([140, 40, 40]), np.array([160, 255, 255]))
        red_mask = cv2.bitwise_or(cv2.bitwise_or(red1, red2), magenta)
        red_ratio = np.count_nonzero(red_mask) / red_mask.size  # ë¹¨ê°„ìƒ‰ ë¹„ìœ¨ ê³„ì‚°

        # íŒŒë€ìƒ‰ ë²”ìœ„ ë§ˆìŠ¤í¬ ìƒì„±
        blue_mask = cv2.inRange(hsv_roi, np.array([90, 70, 50]), np.array([130, 255, 255]))
        blue_ratio = np.count_nonzero(blue_mask) / blue_mask.size  # íŒŒë€ìƒ‰ ë¹„ìœ¨ ê³„ì‚°

        # ìƒ‰ìƒ ê°€ì¤‘ì¹˜ (ë¹¨ê°„íŒ€ ê°ì§€ë¥¼ ë” ê°•í™”í•¨)
        red_weight = 3.0
        blue_weight = 2.0
        red_weighted = red_ratio * red_weight
        blue_weighted = blue_ratio * blue_weight

        # íŒ€ ë¶„ë¥˜ ê¸°ì¤€ threshold
        red_thresh = 0.01
        blue_thresh = 0.01

        # ìƒ‰ìƒ ë¹„ìœ¨ì— ë”°ë¼ íŒ€ ë¶„ë¥˜
        if red_weighted > blue_weighted and red_weighted > red_thresh:
            team_color = (0, 0, 255)  # ë¹¨ê°„íŒ€ (BGR)
            team_name = "Red Team"
        elif blue_weighted > red_weighted and blue_weighted > blue_thresh:
            team_color = (255, 0, 0)  # íŒŒë€íŒ€ (BGR)
            team_name = "Blue Team"
        else:
            team_color = (0, 255, 0)  # ì•Œ ìˆ˜ ì—†ìŒ -> ì´ˆë¡ìƒ‰
            team_name = "Unknown"

        # í˜„ì¬ ì„ ìˆ˜ì˜ ì¤‘ì‹¬ ì¢Œí‘œ ì €ì¥
        current_players[obj_id] = (cx, cy)
        player_colors[obj_id] = team_color  # í•´ë‹¹ ì„ ìˆ˜ íŒ€ ì»¬ëŸ¬ ì €ì¥

        # ì†ë„ ë° ì´ ì´ë™ê±°ë¦¬ ê³„ì‚°
        current_pos = (cx, cy)
        if obj_id in player_last_positions:
            prev_pos = player_last_positions[obj_id]  # ì´ì „ ìœ„ì¹˜
            pixel_dist = euclidean(prev_pos, current_pos)  # í”½ì…€ ê±°ë¦¬ ê³„ì‚°
            real_dist_m = pixel_dist * pixel_to_meter  # ì‹¤ì œ ê±°ë¦¬(m)ë¡œ ë³€í™˜
            speed_kmh = (real_dist_m * fps) * 3.6  # ì†ë„ ê³„ì‚° (km/h)
            player_distances[obj_id] += real_dist_m  # ëˆ„ì  ì´ë™ê±°ë¦¬ ê°±ì‹ 

            # ì†ë„ì™€ ì´ ì´ë™ê±°ë¦¬ ì˜ìƒì— í‘œì‹œ
            cv2.putText(frame_copy, f"{speed_kmh:.1f} km/h", (cx, cy + 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, team_color, 2)
            cv2.putText(frame_copy, f"Total: {player_distances[obj_id]:.1f} m", (cx, cy + 35),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, team_color, 2)

        # í˜„ì¬ ìœ„ì¹˜ ê°±ì‹ 
        player_last_positions[obj_id] = current_pos

        # ì‚¬ëŒ ê²½ê³„ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), team_color, 2)
```



#### 5.5. Ball Detection

**Purpose:**

 Used to detect the ball in real time, determine the ballâ€™s movement path, and judge events such as goals, throw-ins, and goal-line outs, as well as to represent team-specific ball possession. Ball detection is also necessary to link events with hardware.



**5.5.1. Code for Ball Detection and Trail Visualization within the Real-Time Video Analysis**

* Since there is only one ball on the field, the prediction mode is used to optimize ball detection. The ball size is set within a specific range to avoid false detections of objects outside that size. To reduce noise, HSV filtering is applied to exclude objects with a high white ratio. The ball used in the video is red, so it is detected when the red component in the HSV color space exceeds a certain threshold. The ballâ€™s trail is visualized by using its previous coordinates, allowing the movement path to be displayed on the image.

```python
# ê³µì„ ì°¾ê¸° ìœ„í•´, ê³µë§Œ íƒì§€í•˜ë©´ ë˜ê¸°ì— predict ì‚¬ìš©
results_ball = model.predict(frame, classes=[32], conf=0.001)

# ê³µ íƒì§€ ë° ì²˜ë¦¬, ê³µì˜ trail í‘œí˜„
    ball_detected = False  # ê³µ ê°ì§€ ì—¬ë¶€

    # ê³µì„ íƒì§€í•œ ê²½ìš°
    if results_ball and results_ball[0].boxes is not None:
        boxes = results_ball[0].boxes
        cls = boxes.cls.cpu().numpy().astype(int)
        xyxy = boxes.xyxy.cpu().numpy()
        confs = boxes.conf.cpu().numpy()

        # ê³µì´ë¼ê³  íŒë‹¨í•  ì‚¬ì´ì¦ˆ ì„ ì •
        min_ball_area = 50
        max_ball_area = 350

        for i, class_id in enumerate(cls):
            if class_id != 32: # cocodatasetì—ì„œ ê³µì˜ idëŠ” 32ë²ˆì„
                continue
            confidence = confs[i]
            if confidence < 0.001: # ì‹ ë¢°ë„ë¥¼ ì¡°ì •í•˜ì—¬ ê³µ ê²€ì¶œ ì§„í–‰
                continue

            x1, y1, x2, y2 = map(int, xyxy[i])
            cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)

            # ê²½ê¸°ì¥ ë°–ì— ìˆëŠ” ê³µì€ íƒì§€ X
            frame_center_x = frame.shape[1] // 2
            if abs(cx) < 300:
                continue

            roi = frame[y1:y2, x1:x2]
            if roi.size == 0:
                continue

            hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

            # íƒì§€í•  ê³µì˜ ìƒ‰ìƒ, í°ìƒ‰ ì—¬ë¶€ íŒë‹¨
            lower_white = np.array([0, 0, 240])
            upper_white = np.array([180, 50, 255])
            white_mask = cv2.inRange(hsv_roi, lower_white, upper_white)
            white_ratio = np.count_nonzero(white_mask) / white_mask.size

            # í°ìƒ‰ì´ ì¼ì •ë²”ìœ„ ì´ìƒ ë„˜ì–´ì„  ê²½ìš° ê³µì´ë¼ê³  íŒë‹¨ ì§„í–‰ X
            if white_ratio > 0.001:
                continue

            # ì˜ìƒì—ì„œ ê³µì˜ ìƒ‰ìƒì€ ë¹¨ê°„ìƒ‰ì´ë¼ ë¹¨ê°„ìƒ‰ì´ ì¡´ì¬í•˜ëŠ” ê³µ íƒì§€ ì§„í–‰
            lower_red1 = np.array([0, 30, 70])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([160, 30, 70])
            upper_red2 = np.array([180, 255, 255])
            red_mask1 = cv2.inRange(hsv_roi, lower_red1, upper_red1)
            red_mask2 = cv2.inRange(hsv_roi, lower_red2, upper_red2)
            red_mask = cv2.bitwise_or(red_mask1, red_mask2)
            red_ratio = np.count_nonzero(red_mask) / red_mask.size
            if red_ratio < 0.05: # ë¹¨ê°„ìƒ‰ì„ í¬í•¨í•˜ì§€ ì•Šì€ ê²½ìš° ê³µì´ë¼ê³  íŒë‹¨ X
                continue

            #ê³µì˜ ë„“ì´ ê³„ì‚°
            width = x2 - x1
            height = y2 - y1
            area = width * height

            # ê³µì˜ ë„“ì´ê°€ íŠ¹ì • ë²”ìœ„ë³´ë‹¤ ë„˜ì–´ì„  ê²½ìš° ê³µì´ë¼ê³  íŒë‹¨ X
            if area < min_ball_area or area > max_ball_area:
                continue

            # ê³µ ì¢Œí‘œ ê¸°ë¡
            ball_positions.append((cx, cy))
            if len(ball_positions) > 10:
                ball_positions.pop(0)

            ball_detected = True  # ê³µ ê°ì§€ë¨
            
            # í•­ìƒ trail ê·¸ë¦¬ê¸° (ê³µ ê°ì§€ ì—¬ë¶€ì™€ ë¬´ê´€)
    if ball_positions:
        # ì—¬ëŸ¬ í”„ë ˆì„ ê²¹ì²˜ì„œ trail ê·¸ë¦¬ê¸°
        overlay = frame_copy.copy()
        trail_len = len(ball_positions)
        for i in range(1, trail_len):
            pt1 = ball_positions[i - 1]
            pt2 = ball_positions[i]

            alpha = i / trail_len
            color = (0, 255, 255)
            thickness = max(5, int(4 * alpha))

            #íˆ¬ëª…ë„ë¥¼ ì´ìš©í•˜ì—¬ ê³µì˜ trail í‘œí˜„ ì§„í–‰
            cv2.line(overlay, pt1, pt2, color, thickness)
            fade = alpha * 0.2
            frame_copy = cv2.addWeighted(overlay, fade, frame_copy, 1 - fade, 0) # íˆ¬ëª…ë„ ì ìš©

```



#### 5.6. Determination and Visualization of Goal-Line Out, Throw-in, and Goal Events

**Purpose:**

 Used to determine whether a goal-line out, throw-in, or goal has occurred, and to trigger hardware accordingly. It is also used to send flags for saving highlight videos.



**5.6.1. Code for Determining Goal-Line Out, Throw-in, and Goal Events within the Real-Time Video Analysis**

* A goal occurs when the ball crosses the goal line within the goalpost coordinates. A goal-line out event is flagged when the ball crosses the line outside of the goalpost area. A throw-in is triggered when the ball goes beyond the sideline. The throw-in flag is cleared only when the ball re-enters the field after coming close to a player.

```python
# ê³µì„ íƒì§€í•œ ê²½ìš°
if results_ball and results_ball[0].boxes is not None:
    boxes = results_ball[0].boxes
    cls = boxes.cls.cpu().numpy().astype(int)
    xyxy = boxes.xyxy.cpu().numpy()
    confs = boxes.conf.cpu().numpy()

    # ê³µì´ë¼ê³  íŒë‹¨í•  ì‚¬ì´ì¦ˆ ì„ ì •
    min_ball_area = 50
    max_ball_area = 350
    
    
    # ê³¨ íŒì •
    if yellow_line:
        # ê³¨ë¼ì¸ ì¢Œí‘œ (ì˜ìƒ ì•„ë˜ ê³¨ëŒ€)
        x_left, x_right, y_left, y_right = yellow_line

        # ê³¨ë¼ì¸ ì¢Œí‘œ (ì˜ìƒ ìœ„ ê³¨ëŒ€)
        x_left_top, x_right_top, y_left_top, y_right_top = yellow_line_top

            #í•´ë‹¹ ê³¨ë¼ì¸ì— ë“¤ì–´ê°„ ê²½ìš° ê³¨ì´ë¼ê³  íŒë‹¨ ì§„í–‰
            if x_left <= cx <= x_right:
                if cy >= 800 and cy > max(y_left, y_right):
                    goal_flag = True # ê³¨ flag
                    goal_frame_counter = goal_display_frames # ê³¨ ë¬¸ìë¥¼ ì¼ì • í”„ë ˆì„ë™ì•ˆ ì¶œë ¥í•˜ê¸° ìœ„í•´
                    red_team_goal_flag = True
                    goal_line_flag=False # ê³¨ë¼ì¸ ì•„ì›ƒ flag ì´ˆê¸°í™”
                    throwin_flag=False # ìŠ¤ë¡œì¸ flag ì´ˆê¸°í™”
                elif cy <= 100 and cy < min(y_left_top, y_right_top):
                    goal_flag = True # ê³¨ flag
                    goal_line_flag=False # ê³¨ë¼ì¸ ì•„ì›ƒ flag ì´ˆê¸°í™”
                    throwin_flag=False # ìŠ¤ë¡œì¸ flag ì´ˆê¸°í™”
                    goal_frame_counter = goal_display_frames # ê³¨ ë¬¸ìë¥¼ ì¼ì • í”„ë ˆì„ë™ì•ˆ ì¶œë ¥í•˜ê¸° ìœ„í•´
                    blue_team_goal_flag = True

            # ê³¨ ë¼ì¸ ì•„ì›ƒ íŒì •
            if cx < x_left or cx > x_right:
                if cy >= 800 and cy > max(y_left, y_right):
                    goal_line_flag = True # ê³¨ë¼ì¸ ì•„ì›ƒ flag
                    goal_line_out_counter = goal_display_frames # ê³¨ ë¼ì¸ ì•„ì›ƒì„ ì¼ì • í”„ë ˆì„ë™ì•ˆ ì¶œë ¥í•˜ê¸° ìœ„í•´
                    throwin_flag=False #ìŠ¤ë¡œì¸ flag ì´ˆê¸°í™”

                elif cy <= 100 and cy < min(y_left_top, y_right_top):
                    goal_line_flag = True # ê³¨ë¼ì¸ ì•„ì›ƒ flag
                    goal_line_out_counter = goal_display_frames # ê³¨ ì•„ì›ƒì„ ì¼ì • í”„ë ˆì„ë™ì•ˆ ì¶œë ¥í•˜ê¸° ìœ„í•´
                    throwin_flag=False #ìŠ¤ë¡œì¸ flag ì´ˆê¸°í™”
        # throwin íŒì •
        # í•´ë‹¹ ê³µì´ ì‚¬ì´ë“œ ë¼ì¸ì„ ë²—ì–´ë‚œ ê²½ìš° ê³¨ë¼ì¸ ì•„ì›ƒì´ë¼ íŒë‹¨ ì§„í–‰
        expected_x = int((cy - left_b) / left_m)
        expected_x_right = int((cy - right_b) / right_m)
        if (cx < expected_x) or ((cx > expected_x_right) and (goal_flag is False) and (goal_line_flag is False)):
            # ìŠ¤ë¡œì¸ flagë§Œ true
            throwin_flag = True
            goal_line_flag = False
            goal_flag = False


        # ê±°ë¦¬ ì²´í¬, ìŠ¤ë¡œì¸ ì§„í–‰ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´
        for player_pos in current_players.values():
            dist = np.linalg.norm(np.array(player_pos) - np.array((cx, cy)))
            if dist < 70: # ìŠ¤ë¡œì¸ ì§„í–‰ ì‹œ ê³µê³¼ ì‚¬ëŒì´ ê°€ê¹Œì›Œ ì¡Œì„ ë•Œ
                throwin_reset_pending = True
                break
        else:
            throwin_reset_pending = False

        # ê³µê³¼ ì‚¬ëŒì´ ë©€ì–´ì¡Œìœ¼ë©° ê³µì´ ê²½ê¸°ì¥ ì•ˆìœ¼ë¡œ ë“¤ì–´ì™”ì„ ë•Œ ìŠ¤ë¡œì¸ íŒë‹¨ ì´ˆê¸°í™”
        if throwin_flag and throwin_reset_pending and cx > expected_x:
            throwin_flag = False
            throwin_reset_pending = False

        break  # ì²« ë²ˆì§¸ ìœ íš¨ ê³µë§Œ ì²˜ë¦¬

```



**5.6.2. Code for Displaying Goal-Line Out, Throw-in, and Goal Events within the Real-Time Video Analysis, with Music Playback for Goals**

* Text corresponding to each event flag is displayed on the image. For goal and goal-line out events, the text remains visible for a predefined number of frames. Additionally, the pre-set music plays when a goal occurs. For throw-in events, the displayed text disappears once the flag is cleared.

```python
# GOAL í‘œì‹œ
    if goal_flag and goal_frame_counter > 0:
        # ê³¨ ë¬¸ì í‘œí˜„
        cv2.putText(frame_copy, "GOAL", (50, 700), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 102), 10)
        goal_frame_counter -= 1
        if goal_frame is None:
            goal_frame = frame_count
            print(f"start frame {goal_frame}")

        # ì¼ì • ì‹œê°„ ê³¨ ë¬¸ìë¥¼ í‘œí˜„í–ˆì„ ë•Œ ì´ˆê¸°í™” ì§„í–‰
        if goal_frame_counter == 0:
            goal_flag = False
            goal_sound_played = False

    # ê³¨ì„ ë„£ì„ ì‹œ ìŒì•… ì¬ìƒ
    if goal_flag and not goal_sound_played and goal_line_flag==0:
        goal_sound.play()
        goal_sound_played = True

    # ê³¨ë¼ì¸ ì•„ì›ƒ í‘œì‹œ
    if goal_line_flag and goal_line_out_counter > 0:
        cv2.putText(frame_copy, "GOAL LINE OUT", (50, 700), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 255), 6)
        goal_line_out_counter -= 1

            # print(f"start frame {goal_frame}")
        if goal_line_out_counter == 0:
            goal_line_flag = False


    # ìŠ¤ë¡œì¸ í‘œí˜„  
    if throwin_flag:
        cv2.putText(frame_copy, "Throw-In", (50, 700), cv2.FONT_HERSHEY_SIMPLEX, 3, (57, 255, 20), 8)
```



#### 5.7. Implementation of 2D Heatmap

**Purpose:**

 Used to visualize playersâ€™ movements in 2D. This allows observation of player movements on the field as seen during the game.



**5.7.1. Code for Implementing the Heatmap within the Real-Time Video Analysis (Considering Actual Futsal Field Dimensions)**

* When drawing the goalposts and lines on the heatmap, the code was adjusted to match the actual proportions of the futsal field. The cv2.getPerspectiveTransform function was used to convert player coordinates into a top-down view of the field. Then, the playersâ€™ and ballâ€™s coordinates were mapped onto the heatmap to visualize their movements.

```python
# íˆíŠ¸ë§µ í¬ê¸° ë° ìƒì„±
mini_map_width, mini_map_height = 520, 300
mini_map = np.ones((mini_map_height, mini_map_width, 3), dtype=np.uint8) * 0
mini_map[:] = (0, 180, 0)  # ë…¹ìƒ‰ ë°°ê²½

# ë¼ì¸ì˜ ìƒ‰ê¹” ë° ë‘ê»˜
line_color = (255, 255, 255)
line_thickness = 2

# ì¤‘ì•™ì„ , ì¤‘ì•™ì›, í˜ë„í‹° ë°•ìŠ¤, ê³¨ëŒ€ ê·¸ë¦¬ê¸°
cv2.line(mini_map, (mini_map_width // 2, 0), (mini_map_width // 2, mini_map_height), line_color, line_thickness)
cv2.circle(mini_map, (mini_map_width // 2, mini_map_height // 2), int(mini_map_height * 9.15 / 68), line_color, line_thickness)

# ì‹¤ì œ íŒ¨ë„í‹° ë°•ìŠ¤ í¬ê¸°ë¥¼ ê³ ë ¤í•´ ë¯¸ë‹ˆë§µì— í‘œí˜„ ì§„í–‰
penalty_box_length = int(mini_map_width * (16.5 / 105))
penalty_box_height = int(mini_map_height * (40.3 / 68))

# íŒ¨ë„í‹° ë°•ìŠ¤ 
left_top = (0, (mini_map_height - penalty_box_height) // 2)
left_bottom = (penalty_box_length, (mini_map_height + penalty_box_height) // 2)
cv2.rectangle(mini_map, left_top, left_bottom, line_color, line_thickness)

right_top = (mini_map_width - penalty_box_length, (mini_map_height - penalty_box_height) // 2)
right_bottom = (mini_map_width, (mini_map_height + penalty_box_height) // 2)
cv2.rectangle(mini_map, right_top, right_bottom, line_color, line_thickness)

# ê³¨ëŒ€ í¬ê¸°, ì‹¤ì œ ê³¨ëŒ€ í¬ê¸°ì˜ ë¹„ìœ¨ì„ ê³ ë ¤í•´ ì ìš©
goal_width = int(mini_map_height * (7.32 / 68))
goal_thickness = 4

# ë¯¸ë‹ˆë§µì— ê³¨ëŒ€ í¬ê¸° ì ìš©
left_goal_y1 = (mini_map_height // 2) - (goal_width // 2)
left_goal_y2 = (mini_map_height // 2) + (goal_width // 2)
cv2.line(mini_map, (2, left_goal_y1), (2, left_goal_y2), line_color, goal_thickness)

right_goal_y1 = (mini_map_height // 2) - (goal_width // 2)
right_goal_y2 = (mini_map_height // 2) + (goal_width // 2)
cv2.line(mini_map, (mini_map_width - 3, right_goal_y1), (mini_map_width - 3, right_goal_y2), line_color, goal_thickness)

# Perspective ë³€í™˜ì„ ìœ„í•œ í¬ì¸íŠ¸ ì„¤ì • 
    # ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë¯¸ë‹ˆë§µìœ¼ë¡œ ë³€í™˜í•  ì›ê·¼ ë³€í™˜ì„ ìœ„í•œ ê¸°ì¤€ì  ì„¤ì •
src_pts = np.float32([
    [750, 40],    # ì¢Œìƒë‹¨ ì  (ê²½ê¸°ì¥ ì›ë³¸ ì¢Œí‘œ ê¸°ì¤€)
    [480, 995],   # ì¢Œí•˜ë‹¨ ì 
    [1760, 995],  # ìš°í•˜ë‹¨ ì 
    [1350, 40]    # ìš°ìƒë‹¨ ì 
])

# ë¯¸ë‹ˆë§µ ìƒì— ëŒ€ì‘ë˜ëŠ” ëª©ì  ì¢Œí‘œ (ì§ì‚¬ê°í˜• í˜•íƒœë¡œ ì •ê·œí™”)
dst_pts = np.float32([
    [0, 0],                             # ì¢Œìƒë‹¨
    [mini_map_width, 0],               # ìš°ìƒë‹¨
    [mini_map_width, mini_map_height], # ìš°í•˜ë‹¨
    [0, mini_map_height]               # ì¢Œí•˜ë‹¨
])

# Perspective Transform í–‰ë ¬ ê³„ì‚°
# src_ptsì˜ 4ì ì„ dst_ptsì˜ 4ì ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ë³€í™˜ í–‰ë ¬ M ìƒì„±
M = cv2.getPerspectiveTransform(src_pts, dst_pts)

# í˜„ì¬ í”„ë ˆì„ì—ì„œ ê°ì§€ëœ ëª¨ë“  ì„ ìˆ˜ ìœ„ì¹˜ë¥¼ ë¯¸ë‹ˆë§µì— í‘œì‹œ
for pid, pos in current_players.items():
    # í˜„ì¬ ì„ ìˆ˜ ìœ„ì¹˜ë¥¼ ë°°ì—´ í˜•íƒœë¡œ ë³€í™˜
    pt = np.array([[[pos[0], pos[1]]]], dtype=np.float32)

    # ì„ ìˆ˜ ìœ„ì¹˜ì— ì›ê·¼ ë³€í™˜ ì ìš©í•˜ì—¬ ë¯¸ë‹ˆë§µ ì¢Œí‘œë¡œ ë³€í™˜
    map_pt = cv2.perspectiveTransform(pt, M)
    map_x, map_y = int(map_pt[0, 0, 0]), int(map_pt[0, 0, 1])

    # ì„ ìˆ˜ì˜ íŒ€ ë˜ëŠ” ê³ ìœ  ìƒ‰ìƒ ì§€ì •
    color = player_colors.get(pid, (255, 255, 255))

    # ë¯¸ë‹ˆë§µì€ yì¶•ì´ ì•„ë˜ë¡œ ê°ˆìˆ˜ë¡ ì¦ê°€í•˜ë¯€ë¡œ flip ì²˜ë¦¬
    map_y = mini_map_height - map_y

    # ë¯¸ë‹ˆë§µì— ì›ìœ¼ë¡œ ì„ ìˆ˜ í‘œì‹œ
    cv2.circle(mini_map, (map_x, map_y), 4, color, -1)

# ê³µì˜ ìœ„ì¹˜ë¥¼ ë¯¸ë‹ˆë§µì— í‘œì‹œ (trailì˜ ê°€ì¥ ë§ˆì§€ë§‰ ìœ„ì¹˜ ì‚¬ìš©)
if ball_positions:
    bx, by = ball_positions[-1]  # ê°€ì¥ ìµœê·¼ í”„ë ˆì„ì˜ ê³µ ìœ„ì¹˜

    # ê³µ ì¢Œí‘œë¥¼ ë°°ì—´ë¡œ ë³€í™˜
    ball_pt = np.array([[[bx, by]]], dtype=np.float32)

    # ê³µ ìœ„ì¹˜ì—ë„ ë™ì¼í•˜ê²Œ ì›ê·¼ ë³€í™˜ ì ìš©
    ball_map_pt = cv2.perspectiveTransform(ball_pt, M)
    map_x, map_y = int(ball_map_pt[0, 0, 0]), int(ball_map_pt[0, 0, 1])

    # yì¶• ë’¤ì§‘ê¸° ì²˜ë¦¬
    map_y = mini_map_height - map_y

    # ë¯¸ë‹ˆë§µì— ê³µ í‘œì‹œ (ë…¸ë€ìƒ‰ ì›)
    cv2.circle(mini_map, (map_x, map_y), 5, (0, 255, 255), -1)



# ë¯¸ë‹ˆë§µ í…Œë‘ë¦¬
cv2.rectangle(mini_map, (0, 0), (mini_map_width - 1, mini_map_height - 1), line_color, 2)

# ë¯¸ë‹ˆë§µ í”„ë ˆì„ ì™¼ìª½ ìƒë‹¨ì— ë¶™ì„
frame_copy[10:10 + mini_map_height, 10:10 + mini_map_width] = mini_map


```



#### 5.8. Ball Possession Visualization

**Purpose:**

 Used to represent each teamâ€™s ball possession and to display this possession on the LED.



**5.8.1. Code for Calculating Team-Specific Ball Possession within the Real-Time Video Analysis**

* Ball possession for each team was calculated. The possession increases for the team closest to the ball, while if both teams are far from the ball, the possession remains unchanged. Additionally, during events such as throw-ins and goal-line outs, the possession of the team currently controlling the ball is increased.

```python
 # ë³¼ ì ìœ ìœ¨ ê³„ì‚°ìš© ë³€ìˆ˜ ì´ˆê¸°í™”
if 'ball_possession_count' not in globals():
    ball_possession_count = {'Red Team': 0, 'Blue Team': 0, 'Unknown': 0}
    ball_owner_distance_thresh = 100  # ê³µê³¼ ì„ ìˆ˜ ê°„ ê±°ë¦¬ ì„ê³„ê°’(px)


    # 3. ì ìœ ìœ¨ ê³„ì‚°
    # ê³µì˜ ê°€ì¥ ìµœê·¼ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸° (trailì—ì„œ ë§ˆì§€ë§‰ ì¢Œí‘œ)
ball_center = ball_positions[-1] if ball_positions else None

# ê³µ ê·¼ì²˜ì— ìˆëŠ” íŒ€ê³¼ ê±°ë¦¬ ì´ˆê¸°í™”
nearest_team = None  # ê³µ ê·¼ì²˜ì— ìˆëŠ” íŒ€(Red Team ë˜ëŠ” Blue Team)
nearest_dist = float('inf')  # ìµœì†Œ ê±°ë¦¬ ì´ˆê¸°ê°’ (ë¬´í•œëŒ€)

# ê³µì´ ê°ì§€ëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
if ball_center:
    # í˜„ì¬ í”„ë ˆì„ì— ìˆëŠ” ëª¨ë“  ì„ ìˆ˜ì— ëŒ€í•´ ë°˜ë³µ
    for pid, pos in current_players.items():
        # ê³µê³¼ ì„ ìˆ˜ ê°„ ê±°ë¦¬ ê³„ì‚° (ìœ í´ë¦¬ë“œ ê±°ë¦¬)
        dist = euclidean(ball_center, pos)
        # ì§€ê¸ˆê¹Œì§€ ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ì„ ìˆ˜ì´ë©´ì„œ, íŠ¹ì • ê±°ë¦¬ ê¸°ì¤€ ì•ˆì¼ ê²½ìš°
        if dist < nearest_dist and dist < ball_owner_distance_thresh:
            nearest_dist = dist  # ìµœì†Œ ê±°ë¦¬ ì—…ë°ì´íŠ¸

            # ì„ ìˆ˜ì˜ ê³ ìœ  ìƒ‰ìƒ(íŒ€ ìƒ‰ìƒ)ì„ ê°€ì ¸ì˜´
            team_color = player_colors.get(pid)

            # ìƒ‰ìƒìœ¼ë¡œë¶€í„° ì†Œì† íŒ€ ê²°ì •
            if team_color == (0, 0, 255):        # ë¹¨ê°„ìƒ‰ -> Red Team
                nearest_team = 'Red Team'
            elif team_color == (255, 0, 0):      # íŒŒë€ìƒ‰ -> Blue Team
                nearest_team = 'Blue Team'

# ê³µ ê·¼ì²˜ì— íŒ€ì´ ê°ì§€ëœ ê²½ìš°ì—ë§Œ í•´ë‹¹ íŒ€ì˜ ì ìœ  íšŸìˆ˜ ëˆ„ì 
if nearest_team:
    ball_possession_count[nearest_team] += 1

# í•­ìƒ ì ìœ ìœ¨ì„ ê³„ì‚° (totalì´ 0ì¸ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬)
total = sum(ball_possession_count.values())
red_pct = (ball_possession_count['Red Team'] / total) * 100 if total else 0
blue_pct = (ball_possession_count['Blue Team'] / total) * 100 if total else 0
```



#### 5.9. Highlight Video Saving

**Purpose:**

  Used to save highlight videos when a goal is scored.



**5.9.1. Code for Saving Highlight Videos upon a Goal**

* When a goal is scored, the video segment from 5 seconds before to 5 seconds after the event is saved. The saved video uses the analyzed footage rather than the original raw video. If no goal is scored, this code does not execute.

```python
# ê³¨ì´ ë°œìƒí•œ ê²½ìš°ì—ë§Œ í•˜ì´ë¼ì´íŠ¸ ì˜ìƒ ì €ì¥ ë° ì „ì†¡ì„ ìˆ˜í–‰
if goal_frame is not 0:
    highlight_margin = 150  # ê³¨ ì£¼ë³€ ì „í›„ í”„ë ˆì„ ìˆ˜ (ì•½ 5ì´ˆ ì „í›„)

    # ê¸°ì¡´ ì˜ìƒ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(output_path)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # ì˜ìƒ ë„ˆë¹„
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # ì˜ìƒ ë†’ì´
    fps = cap.get(cv2.CAP_PROP_FPS)                         # í”„ë ˆì„ ì†ë„
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))   # ì´ í”„ë ˆì„ ìˆ˜

    if goal_frame is not None:
        # ì‹œì‘/ë í”„ë ˆì„ ê³„ì‚° (ì˜ìƒ ë²”ìœ„ ì´ˆê³¼ ë°©ì§€)
        start_frame = max(0, goal_frame - highlight_margin)
        end_frame = min(total_frames - 1, goal_frame + highlight_margin)

        # í•˜ì´ë¼ì´íŠ¸ ì˜ìƒ ì €ì¥ì„ ìœ„í•´ ê¸°ì¡´ì— ì´ë¯¸ì§€ ì²˜ë¦¬í•œ ì˜ìƒì„ ë‹¤ì‹œ ì¶œë ¥ ì§„í–‰
        cap = cv2.VideoCapture(output_path)
        if not cap.isOpened():
            print("ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨")
            exit()

        # í•˜ì´ë¼ì´íŠ¸ ì˜ìƒ ì €ì¥
        out = cv2.VideoWriter(
            "./output_video/highlight.mp4",                   # ì €ì¥ ê²½ë¡œ
            cv2.VideoWriter_fourcc(*"mp4v"),                  # ì½”ë± ì„¤ì •
            fps,                                              # í”„ë ˆì„ ì†ë„
            (frame_width, frame_height)                       # ì˜ìƒ í•´ìƒë„
        )

        current_frame = 0  # í˜„ì¬ í”„ë ˆì„ ì¸ë±ìŠ¤
        while cap.isOpened():
            ret, frame = cap.read()  # í”„ë ˆì„ ì½ê¸°
            if not ret:
                break
            current_frame += 1
            # í•˜ì´ë¼ì´íŠ¸ ë²”ìœ„ ë‚´ í”„ë ˆì„ë§Œ ì €ì¥
            if current_frame <= end_frame and current_frame >= start_frame:
                out.write(frame)

        cap.release()
        out.release()
        print("highlight.mp4 ì €ì¥ ì™„ë£Œ!")
```



#### 5.10. Email Sending

**Purpose:**

 Used to automatically send highlight videos to the team that scored a goal.



**5.10.1. Code for Sending Emails within VS Code**

* The highlight video is automatically sent to the team that scored. This code does not run if no goal is scored. The receiver_email variable should be set with the email addresses of the recipients. The senderâ€™s email address must be configured by the user. Additionally, the recipientâ€™s app-specific password is required for the email to be sent successfully.

```python
# ì´ë©”ì¼ ì „ì†¡ ì„¤ì •
import smtplib
from email.message import EmailMessage

# ë°œì‹ ì ì´ë©”ì¼
sender_email = "????@handong.ac.kr"
receiver_email = None  # ìˆ˜ì‹ ì ì´ë©”ì¼ì€ ê³¨ ìƒí™©ì— ë”°ë¼ ì„¤ì •

# ê³¨ ìƒí™©ì— ë”°ë¼ ìˆ˜ì‹ ì ê²°ì •
if red_team_goal_flag == 1:
    receiver_email = "????@gmail.com"
elif blue_team_goal_flag == 1:
    receiver_email = "????@handong.ac.kr"

# ì´ë©”ì¼ ì œëª© ë° ë³¸ë¬¸
subject = "Highlight Video"
body = "ì²¨ë¶€ëœ ì˜ìƒì€ í•˜ì´ë¼ì´íŠ¸ ì˜ìƒì…ë‹ˆë‹¤."

# Gmail ì•± ë¹„ë°€ë²ˆí˜¸ (2ë‹¨ê³„ ì¸ì¦ ì‚¬ìš© ì‹œ ì•± ë¹„ë°€ë²ˆí˜¸ í•„ìš”), ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¼ ë³€ê²½ì´ í•„ìš”í•¨
password = "???? ???? ???? ????"

# ìˆ˜ì‹ ìê°€ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ì´ë©”ì¼ ì „ì†¡
if receiver_email:
    msg = EmailMessage()
    msg["Subject"] = subject
    msg["From"] = sender_email
    msg["To"] = receiver_email
    msg.set_content(body)

    # í•˜ì´ë¼ì´íŠ¸ ì˜ìƒ ì²¨ë¶€
    file_path = "./output_video/highlight.mp4"
    with open(file_path, "rb") as f:
        file_data = f.read()
        msg.add_attachment(file_data, maintype="video", subtype="mp4", filename="highlight.mp4")

    # Gmail SMTP ì„œë²„ë¥¼ í†µí•´ ì´ë©”ì¼ ì „ì†¡
    with smtplib.SMTP_SSL("smtp.gmail.com", 465) as smtp:
        smtp.login(sender_email, password)
        smtp.send_message(msg)

    print("ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ!")
else:
    print("goal flagê°€ ê°ì§€ë˜ì§€ ì•Šì•„ ì´ë©”ì¼ì„ ì „ì†¡í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
```



<img src="./img/app_password.jpg" alt="app_password" style="zoom: 67%;" />

<center><strong>Figure 8. Process for generating an app password</strong></center>

Information related to app password setup: [click](https://support.google.com/accounts/answer/185833?hl=ko)



<img src="./img/email_total.png" alt="email_total" style="zoom:55%;" />

<center><strong>Figure 9. How to send an email in VS Code (a) App password of the sender's email account (b) Sender's email address (c) Recipient's email address</strong></center>

---



### 6. Arduino Code (Optional)

 The following Arduino code controls two WS2812B RGB LED rings using the FastLED library. One ring  displays real-time ball possession percentages between the red and blue teams, and the other  reacts to in-game events such as goals, throw-ins, and goal line outs.

**Full Code**: [Github Link](https://github.com/LeeJunjae1/DLIIP_FINAL_21700766_DongjunHan_22000573_JunjaeLee) (Download all files from the repository to run the program)



#### 6.1 Hardware Requirements

- **ESP32 board** (e.g., LOLIN D32, ESP32 DevKit v1, etc.)
- **2 Ã— WS2812B RGB LED rings** (each with 24 LEDs)
- **External 5V power supply** (recommended if LED brightness is high)
- **330â€“470Î© resistor** between ESP32 data pin and first LED (optional but improves signal quality)
- **1000ÂµF capacitor** between VCC and GND of LED power (optional but protects against voltage spikes)
- **Common ground** between ESP32 and LED power supply



#### 6.2 Software Requirements

- **Arduino IDE**: https://www.arduino.cc/en/software

- **ESP32 Board Package**:

  - Arduino IDE â†’ Preferences â†’ Add URL:

    ```
    https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json
    ```

  - Then go to: Tools > Board > Boards Manager, search â€œESP32â€ and install.

![arduino_total1](./img/arduino_total1.png)

<center><strong>Figure 10. How to install ESP32 on Arduino</strong></center>



<img src="./img/arduino(3).png" alt="arduino_3" style="zoom:55%;" />

<center><strong>Figure 12. How to select the ESP32 board in Arduino</strong></center>



- **FastLED Library**:

  - Arduino IDE â†’ Sketch > Include Library > Manage Libraries
  - Search for FastLED and install (by Daniel Garcia)

![arduino_total2](./img/arduino_total2.png)

<center><strong>Figure 13. How to configure the Library</strong></center>



#### 6.3 Pin Configuration and LED Mapping

| Purpose        | Pin # | Variable     | LED Array         |
| -------------- | ----- | ------------ | ----------------- |
| Possession LED | 27    | leds_score[] | Red/Blue ratio    |
| Event LED      | 26    | leds_event[] | Goal/Throw-in/Out |

 Make sure the number of LEDs matches your actual hardware (in this example, NUM_LEDS = 24).



#### 6.4 Serial Input Protocol

- Serial communication is handled via a Python script running in VS Code, not through the Arduino Serial Monitor.

  The ESP32 listens for newline-terminated (\n) strings over serial. These strings represent either possession data or game event commands. The input is parsed within the loop() function and used to update the LED arrays accordingly.

  #### Input Format

  - **Possession Update**:
    A string like "60,40" indicates 60% possession for the red team and 40% for the blue team.

  - **Event Commands**:

    - "GOAL" â€“ triggers a rainbow animation

    - "THROWIN" â€“ triggers solid neon green

    - "OUT" â€“ triggers solid neon purple

      

#### 6.5 LED Display Logic

**6.5.1. Possession Display**

- Function: displayPossession()
- Calculates how many LEDs should be red vs blue using red_percent and NUM_LEDS
- Only leds_score[] is updated
- 

**6.5.2. Event Display**

- Function: handleEventLEDs()
- Depending on the command (GOAL, THROWIN, OUT):
  - **GOAL**: Rainbow color animation using HSV
  - **THROWIN**: Neon green (RGB: 57, 255, 20)
  - **OUT**: Neon purple (RGB: 255, 0, 255)
  - **Default**: White (no active event)



#### 6.6 Upload & Run

1. Connect the ESP32 to your PC via USB.

2. Open the Arduino IDE or VS Code with PlatformIO and upload the sketch to your ESP32

3. Make sure your Python script is connected to the correct COM port at 115200 baud

4. The Python script automatically sends possession updates and event triggers over serial to the ESP32:

   - For example:

     ```python
     ser.write("GOAL\n".encode())
     ser.write("60,40\n".encode())
     ```

5. The ESP32 receives these strings and updates the LEDs in real time:

   - leds_score[] reflects possession (red vs blue)
   - leds_event[] reflects events (goal, throw-in, out)

 No manual input is required via the Serial Monitor. All communication is handled automatically through the Python script.

## Results and Analysis

### 1. Results of Problem 1 ~ 5

![1_5_total](./img/1_5_total.png)

<center><strong>Figure 14. Result image for Problem 1~5</strong></center>

| No.  | Feature                                          | Criteria Summary                                             | Evaluation Result | Remarks                                                      |
| ---- | ------------------------------------------------ | ------------------------------------------------------------ | ----------------- | ------------------------------------------------------------ |
| 1    | **Detect players by team color**                 | - Players must be classified into two teams (e.g., red vs. blue) based on jersey color using HSV thresholding. - Target accuracy: â‰¥ **90%** correct classification per frame. | âœ” Achieved        | All players were clearly distinguished using red and blue bounding boxes with consistent results (**100%**). No team misclassifications observed. |
| 2    | **Detect the ball**                              | - Ball must be detected and tracked in frames where it is visible. - Target accuracy: â‰¥ **85%** presence across visible frames. - Must handle motion blur and partial occlusions. | âœ” Achieved        | The ball is consistently detected with a bounding box across frames, even under fast motion. Tracking remained stable. The ball cannot be detected when it is occluded by a player, but in all other situations, it is detected with **100%** accuracy. |
| 3    | **Visual trail effect for the ball**             | - A fading trail should visualize the last few seconds (e.g., 1.5s or 45 frames). - Must update in real-time with transparency fading. | âœ” Achieved        | A smooth yellow arc representing the ballâ€™s recent trajectory is clearly visible, helping illustrate direction and movement. |
| 4    | **Display player speed (km/h)**                  | - Speed must be calculated based on frame-to-frame position changes. - Calibrated to real-world scale. - Value displayed above each playerâ€™s bounding box. | âœ” Achieved        | Each player has a clearly labeled speed (e.g., "20.4 km/h") rendered in real time above their bounding box. Units are accurate and visually distinguishable. |
| 5    | **Display player activity (distance in meters)** | - Cumulative distance must be tracked per player. - Acceptable error margin: within Â±10% of actual distance based on calibration. | âœ” Achieved        | The label "Total: x.x m" updates per player as they move. Distance accumulates accurately and smoothly, even across varying speeds. |

* Although speed and activity level are visualized in the video, it is necessary to compare them with real values to verify their accuracy.



### 2. Result of Problem 6

![6_total](./img/6_total.png)

<center><strong>Figure 15. Result image for Problem 6</strong></center>

| No.  | Feature                              | Criteria Summary                                             | Evaluation Result | Remarks                                                      |
| ---- | ------------------------------------ | ------------------------------------------------------------ | ----------------- | ------------------------------------------------------------ |
| 6    | **Display team ball possession (%)** | - Possession calculated based on time of control (nearest player to the ball per frame). - Updated every second. - Displayed in percentage format (e.g., "Red: 63.7%"). - Shown visually via UI or external LED (optional). | âœ” Achieved        | The possession rate is updated in real-time and clearly displayed as "Red Possession: 76.8%" and "Blue Possession: 23.2%". The values are precise, readable, and reflect ball proximity logic accurately. |





### 3. Results of Problem 7 ~ 8

![8_total](./img/8_total.png)

<center><strong>Figure 16. Result image for Problem 7~8 (a) Original analyzed video (b) Throw-In event result(c) Goal Line Out event result (d) Goal event result</strong></center>

| No.  | Feature                                                      | Criteria Summary                                             | Evaluation Result | Remarks                                                      |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------- | ------------------------------------------------------------ |
| 7    | **Draw field lines (corner, sideline, goal) with different colors** | - Use homography to align field lines to actual layout. - Different colors for each line type (e.g., red: goal, green: sideline, purple: corner). - Lines must align within Â±20 pixels of actual field lines for 95% of the video duration. | âœ” Achieved        | Field lines are clearly rendered in distinct colors and correctly mapped to the field boundaries using homography. Sidelines (green), goal lines (yellow), and corners (purple) are consistent and stable throughout the footage. |
| 8    | **Detect and classify ball out-of-bound events**             | - Detect when the ball crosses field boundaries. - Classify events as `"GOAL"`, `"OUT"`, `"THROW-IN"`, `"CORNER"` based on location and context. - Display event type visually (e.g., text or LED). - Log with timestamp. | âœ” Achieved        | "Throw-In" event was correctly detected and displayed in real time with green text. The ball crossing the sideline was properly classified and reflected in the interface. Classification logic based on ball position and context is functioning as expected. |



### 4. Result of Problem 9

![9_total](./img/9_total.png)

<center><strong>Figure 17. Result image for Problem 9</strong></center>

| No.  | Feature                                    | Criteria Summary                                             | Evaluation Result | Remarks                                                      |
| ---- | ------------------------------------------ | ------------------------------------------------------------ | ----------------- | ------------------------------------------------------------ |
| 9    | **Generate 2D heatmap of player movement** | - Accumulate player positions and generate a 2D spatial heatmap per team or per player. - Must reflect frequency or density of presence over time. - Should align with the actual field layout (e.g., top-down view). - Output resolution: at least 50Ã—30 grid cells. | âœ” Achieved        | The heatmap displays colored points corresponding to accumulated player positions, with red and blue dots showing team presence across the field. The layout matches the actual field size and orientation, and position mapping is consistent with visual tracking results. |



### 5. Result of Problem 10

![10_total](./img/10_total.png)

<center><strong>Figure 18. Result image for Problem 10 (a) Goal event occurred (b) Highlight video saved (c) Email sent successfully</strong></center>

| No.  | Feature                                          | Criteria Summary                                             | Evaluation Result | Remarks                                                      |
| ---- | ------------------------------------------------ | ------------------------------------------------------------ | ----------------- | ------------------------------------------------------------ |
| 10   | **Create goal highlight clip and send by email** | - Upon detecting a "GOAL" event, automatically save a 10-second video (5 seconds before and after). - Export as .mp4 (under 20MB). - Email sent with the highlight as an attachment. | âœ” Achieved        | A goal event triggers a clearly labeled highlight video, saved in the correct directory and format. The email is successfully sent with the video (highlight.mp4) attached and includes a clear subject line and message body. The process is fully automated. |

